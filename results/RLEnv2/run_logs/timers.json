{
    "name": "root",
    "gauges": {
        "Crawler.Policy.Entropy.mean": {
            "value": 1.3504427671432495,
            "min": 1.3483116626739502,
            "max": 1.4371016025543213,
            "count": 2575
        },
        "Crawler.Policy.Entropy.sum": {
            "value": 1313.9808349609375,
            "min": 1272.042236328125,
            "max": 1518.8167724609375,
            "count": 2575
        },
        "Crawler.Environment.EpisodeLength.mean": {
            "value": 466.25,
            "min": 4.803468208092486,
            "max": 999.0,
            "count": 2572
        },
        "Crawler.Environment.EpisodeLength.sum": {
            "value": 1865.0,
            "min": 5.0,
            "max": 2005.0,
            "count": 2572
        },
        "Crawler.Step.mean": {
            "value": 2574942.0,
            "min": 993.0,
            "max": 2574942.0,
            "count": 2575
        },
        "Crawler.Step.sum": {
            "value": 2574942.0,
            "min": 993.0,
            "max": 2574942.0,
            "count": 2575
        },
        "Crawler.Policy.ExtrinsicValueEstimate.mean": {
            "value": 203.83184814453125,
            "min": -301.83917236328125,
            "max": 304.2807922363281,
            "count": 2575
        },
        "Crawler.Policy.ExtrinsicValueEstimate.sum": {
            "value": 3668.97314453125,
            "min": -4829.4267578125,
            "max": 4872.08349609375,
            "count": 2575
        },
        "Crawler.Environment.CumulativeReward.mean": {
            "value": 1387.0573091357946,
            "min": -0.9958170962756907,
            "max": 3631.2592163085938,
            "count": 2575
        },
        "Crawler.Environment.CumulativeReward.sum": {
            "value": 5548.229236543179,
            "min": -172.10188460350037,
            "max": 5548.229236543179,
            "count": 2575
        },
        "Crawler.Policy.ExtrinsicReward.mean": {
            "value": 1387.0573091357946,
            "min": -0.9958170962756907,
            "max": 3631.2592163085938,
            "count": 2575
        },
        "Crawler.Policy.ExtrinsicReward.sum": {
            "value": 5548.229236543179,
            "min": -172.10188460350037,
            "max": 5548.229236543179,
            "count": 2575
        },
        "Crawler.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2575
        },
        "Crawler.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2575
        },
        "Worm.Policy.Entropy.mean": {
            "value": 1.8885859251022339,
            "min": 1.4189382791519165,
            "max": 1.8885859251022339,
            "count": 2575
        },
        "Worm.Policy.Entropy.sum": {
            "value": 1869.7000732421875,
            "min": 1341.24169921875,
            "max": 1964.4796142578125,
            "count": 2575
        },
        "Worm.Step.mean": {
            "value": 2574956.0,
            "min": 960.0,
            "max": 2574956.0,
            "count": 2575
        },
        "Worm.Step.sum": {
            "value": 2574956.0,
            "min": 960.0,
            "max": 2574956.0,
            "count": 2575
        },
        "Worm.Policy.ExtrinsicValueEstimate.mean": {
            "value": 3.7047600746154785,
            "min": -17.89284896850586,
            "max": 98.12074279785156,
            "count": 2575
        },
        "Worm.Policy.ExtrinsicValueEstimate.sum": {
            "value": 59.276161193847656,
            "min": -286.28558349609375,
            "max": 1584.6207275390625,
            "count": 2575
        },
        "Worm.Environment.EpisodeLength.mean": {
            "value": 558.0,
            "min": 19.0,
            "max": 999.0,
            "count": 2565
        },
        "Worm.Environment.EpisodeLength.sum": {
            "value": 1116.0,
            "min": 19.0,
            "max": 1987.0,
            "count": 2565
        },
        "Worm.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2575
        },
        "Worm.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 2575
        },
        "Worm.Environment.CumulativeReward.mean": {
            "value": 27.103219881653786,
            "min": 0.0,
            "max": 68.3067033290863,
            "count": 2574
        },
        "Worm.Environment.CumulativeReward.sum": {
            "value": 54.20643976330757,
            "min": 0.0,
            "max": 172.90171012282372,
            "count": 2574
        },
        "Worm.Policy.ExtrinsicReward.mean": {
            "value": 27.103219881653786,
            "min": 0.0,
            "max": 68.3067033290863,
            "count": 2574
        },
        "Worm.Policy.ExtrinsicReward.sum": {
            "value": 54.20643976330757,
            "min": 0.0,
            "max": 172.90171012282372,
            "count": 2574
        },
        "Crawler.Losses.PolicyLoss.mean": {
            "value": 0.028669751674169675,
            "min": 0.013614564951664458,
            "max": 0.1081705511858066,
            "count": 250
        },
        "Crawler.Losses.PolicyLoss.sum": {
            "value": 0.028669751674169675,
            "min": 0.013614564951664458,
            "max": 0.1081705511858066,
            "count": 250
        },
        "Crawler.Losses.ValueLoss.mean": {
            "value": 352.2230244954427,
            "min": 0.030591044947504996,
            "max": 7137.677945963542,
            "count": 250
        },
        "Crawler.Losses.ValueLoss.sum": {
            "value": 352.2230244954427,
            "min": 0.030591044947504996,
            "max": 7137.677945963542,
            "count": 250
        },
        "Crawler.Policy.LearningRate.mean": {
            "value": 0.00029229540856819797,
            "min": 0.00029229540856819797,
            "max": 0.0002999692680102439,
            "count": 250
        },
        "Crawler.Policy.LearningRate.sum": {
            "value": 0.00029229540856819797,
            "min": 0.00029229540856819797,
            "max": 0.0002999692680102439,
            "count": 250
        },
        "Crawler.Policy.Epsilon.mean": {
            "value": 0.19743180199999996,
            "min": 0.19743180199999996,
            "max": 0.199989756,
            "count": 250
        },
        "Crawler.Policy.Epsilon.sum": {
            "value": 0.19743180199999996,
            "min": 0.19743180199999996,
            "max": 0.199989756,
            "count": 250
        },
        "Crawler.Policy.Beta.mean": {
            "value": 0.0048718469198,
            "min": 0.0048718469198,
            "max": 0.004999488824399999,
            "count": 250
        },
        "Crawler.Policy.Beta.sum": {
            "value": 0.0048718469198,
            "min": 0.0048718469198,
            "max": 0.004999488824399999,
            "count": 250
        },
        "Worm.Losses.PolicyLoss.mean": {
            "value": 0.02277741986778589,
            "min": 0.010699927213136107,
            "max": 0.1666545749641955,
            "count": 250
        },
        "Worm.Losses.PolicyLoss.sum": {
            "value": 0.02277741986778589,
            "min": 0.010699927213136107,
            "max": 0.1666545749641955,
            "count": 250
        },
        "Worm.Losses.ValueLoss.mean": {
            "value": 1.9649245937665303,
            "min": 0.8574188371499379,
            "max": 3548.398373222351,
            "count": 250
        },
        "Worm.Losses.ValueLoss.sum": {
            "value": 1.9649245937665303,
            "min": 0.8574188371499379,
            "max": 3548.398373222351,
            "count": 250
        },
        "Worm.Policy.LearningRate.mean": {
            "value": 0.0002922970675676449,
            "min": 0.0002922970675676449,
            "max": 0.0002999692410102529,
            "count": 250
        },
        "Worm.Policy.LearningRate.sum": {
            "value": 0.0002922970675676449,
            "min": 0.0002922970675676449,
            "max": 0.0002999692410102529,
            "count": 250
        },
        "Worm.Policy.Epsilon.mean": {
            "value": 0.19743235500000003,
            "min": 0.19743235500000003,
            "max": 0.199989747,
            "count": 250
        },
        "Worm.Policy.Epsilon.sum": {
            "value": 0.19743235500000003,
            "min": 0.19743235500000003,
            "max": 0.199989747,
            "count": 250
        },
        "Worm.Policy.Beta.mean": {
            "value": 0.004871874514499999,
            "min": 0.004871874514499999,
            "max": 0.004999488375300001,
            "count": 250
        },
        "Worm.Policy.Beta.sum": {
            "value": 0.004871874514499999,
            "min": 0.004871874514499999,
            "max": 0.004999488375300001,
            "count": 250
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1763338295",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\dekum\\miniconda3\\envs\\mlagents\\Scripts\\mlagents-learn config/tagEnvV2.yaml --run-id=RLEnv2 --no-graphics --env=C:\\Users\\dekum\\OneDrive\\Escritorio\\Trabajo\\Proyecto_RL\\build\\My project.exe --torch-device cuda --force",
        "mlagents_version": "1.2.0.dev0",
        "mlagents_envs_version": "1.2.0.dev0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.5.1+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1763355926"
    },
    "total": 17628.864019400004,
    "count": 1,
    "self": 0.17246150000210037,
    "children": {
        "run_training.setup": {
            "total": 0.09286680000150227,
            "count": 1,
            "self": 0.09286680000150227
        },
        "TrainerController.start_learning": {
            "total": 17628.5986911,
            "count": 1,
            "self": 28.138531199321733,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.735662400002184,
                    "count": 1,
                    "self": 6.735662400002184
                },
                "TrainerController.advance": {
                    "total": 17593.64440160068,
                    "count": 2595623,
                    "self": 35.61962718892755,
                    "children": {
                        "env_step": {
                            "total": 16186.38148451173,
                            "count": 2595623,
                            "self": 6517.28335401545,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 9650.917004900151,
                                    "count": 2595623,
                                    "self": 170.50444149630493,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 9480.412563403846,
                                            "count": 5151110,
                                            "self": 9480.412563403846
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 18.181125596129277,
                                    "count": 2595622,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 17573.162960203976,
                                            "count": 2595622,
                                            "is_parallel": true,
                                            "self": 12864.129555104104,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00039059999835444614,
                                                    "count": 2,
                                                    "is_parallel": true,
                                                    "self": 0.00015039999925647862,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00024019999909796752,
                                                            "count": 10,
                                                            "is_parallel": true,
                                                            "self": 0.00024019999909796752
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 4709.033014499873,
                                                    "count": 2595622,
                                                    "is_parallel": true,
                                                    "self": 203.11513371800174,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 202.25525770143577,
                                                            "count": 2595622,
                                                            "is_parallel": true,
                                                            "self": 202.25525770143577
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 3462.596475092909,
                                                            "count": 2595622,
                                                            "is_parallel": true,
                                                            "self": 3462.596475092909
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 841.0661479875271,
                                                            "count": 5191244,
                                                            "is_parallel": true,
                                                            "self": 368.40295616361254,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 472.66319182391453,
                                                                    "count": 25956220,
                                                                    "is_parallel": true,
                                                                    "self": 472.66319182391453
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1371.643289900021,
                            "count": 5191244,
                            "self": 45.01194909881451,
                            "children": {
                                "process_trajectory": {
                                    "total": 498.4596425012169,
                                    "count": 5191244,
                                    "self": 497.96489340121843,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.49474909999844385,
                                            "count": 10,
                                            "self": 0.49474909999844385
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 828.1716982999897,
                                    "count": 500,
                                    "self": 605.1644110998204,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 223.00728720016923,
                                            "count": 15000,
                                            "self": 223.00728720016923
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.08009589999710442,
                    "count": 1,
                    "self": 0.0017498000015621074,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.07834609999554232,
                            "count": 2,
                            "self": 0.07834609999554232
                        }
                    }
                }
            }
        }
    }
}